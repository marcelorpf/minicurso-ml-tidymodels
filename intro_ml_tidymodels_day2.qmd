---
title: "Introdução à Aprendizagem de Máquina com Tidymodels"
subtitle: "<br>XV Semana de Estatística - UFES, Vitória/ES <br> 7 a 8 de novembro de 2024"
author: "Prof. Marcelo R. P. Ferreira"
institute: "DE/UFPB -- PPGMDS/UFPB"
format:
  revealjs:
    theme: beige
    transition: slide
    footer: "Introdução à Aprendizagem de Máquina com Tidymodels - [Prof. Marcelo R. P. Ferreira](http://www.de.ufpb.br/~marcelo)"
    slide-number: true
    show-slide-number: all
    standalone: true
    embed-resources: true
    self-contained-math: true
    html-math-method: mathjax
    execute:
      echo: true
      eval: true
      output: true
      warning: true
      message: true
    include-in-header:
      text: |
        <style>
        #title-slide .title {
          font-size: 2.5em;
          color: #b22222;
        }
        .caption {
          text-align: center;
        }
        .title-slide h2 {
          text-align: center;
        }
        .whiteslide {
          background-color: white;
        }
        </style>
---

## Qual é o nosso plano? {.smaller}

:::: {.columns}

::: {.column width="50%"}
**Dia 1**:

- Aprendizagem de máquina
  - Conceitos básicos;
  - Tipos de Aprendizagem de Máquina;
  - Dados estruturados e não-estruturados;
  - Pré-processamanto de dados;
  - Avaliação de modelos;
  - Particionamento de dados:
    - *Holdout* e $K$-*fold cross-validation*;
  - Otimização de hiperparâmetros:
    - *Grid search* e *Grid search* via *racing*.
:::

::: {.column width="50%"}
![](ml_brain.jpeg){fig-align='center'}
:::

::::

## Qual é o nosso plano? {.smaller}

:::: {.columns}

::: {.column width="50%"}
**Dia 2**:

- `tidymodels`
  - Introdução;
  - Particionamento de dados:`rsample`;
  - O que constitui um modelo: `parsnip`;
  - Pré-processamento e feature engineering: `recipes`;
  - Avaliação de modelos: `yardstick`;
  - Otimização de hiperparâmetros: `tune`;
  - Avaliando muitos modelos: `workflowsets`.
:::

::: {.column width="50%"}
![](tidymodels.jpeg){fig-align='center'}
:::

::::

# A biblioteca `tidymodels`

## A biblioteca `tidymodels` {.smaller}

![](tidymodels_site.jpeg){fig-align='center'}

## A biblioteca `tidymodels` {.smaller}

- Assim como a `tidyverse` é uma meta-biblioteca que consiste de diversas bibliotecas como `ggplot2` e `dplyr`, [`tidymodels`](https://www.tidymodels.org/) é uma meta-biblioteca que consiste das seguintes bibliotecas:
  - `rsample`: funções para particionamento e reamostragem eficiente de dados;
  - `parsnip`: interface unificada para um amplo conjunto de modelos que podem ser testados sem que o usuário se preocupe com diferenças de sintaxe;
  - `recipes`: pré-processamento e *feature engineering*;
  - `tune`: otimização de hiperparâmetros;
  - `yardstick`: funções para avaliar a efetividade de modelos através de medidas de performance.
  
## A biblioteca `tidymodels` {.smaller}

- Outras bibliotecas são carregadas junto com `tidymodels`, como, por exemplo:
  - `workflows`: junta pré-processamento, modelagem (treinamento) e pós-processamento;
  - `workflowsets`: cria conjuntos de workflows;
  - `broom`: converte a informação contida em objetos comuns de `R` para o formato *tidy*;
  - `dials`: cria e gerencia hiperparâmetros de ajuste e *grids* de hiperparâmetros.
  
- Bibliotecas adicionais dentro do fluxo de trabalho de aprendizagem de máquina:
  - `finetune`: permite um processo de otimização de hiperparâmetros mais eficiente;
  - `DALEX`: ferramentas oara interpretação de modelos;
  - `DALEXtra`: extensões para a biblioteca `DALEX`.

## A biblioteca `tidymodels` {.smaller}

```{r}
library(tidymodels)
```

## Conjunto de dados {.smaller}

- Vamos considerar, inicialmente, um conjunto de dados bastante conhecido, o *Palmer Station penguin data*, que contém mensurações obtidas de diferentes espécies de pinguins.

```{r}
library(tidyverse)

df <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-28/penguins.csv')
```

## Conjunto de dados {.smaller}

```{r}
glimpse(df)
```

```{r}
df %>% summary()
```

## Conjunto de dados {.smaller}

- Por hora, vamos excluir as linhas que contém valores ausentes:

```{r}
df <- df[complete.cases(df),]
```

- Também vamos definir as variáveis qualitativas como fatores e a variável ano, que só tem três valores distintos, como um fator ordinal:
```{r}
df <- df %>%
  mutate(across(where(is.character), as.factor))

df$year <- factor(df$year, ordered = TRUE)

glimpse(df)
```

## Particionamento de dados:`rsample` {.smaller}

- Vamos particionar o conjunto de dados em 75% para treinamento e 25% para teste;

- Para isso, vamos utilizar a função `initial_split()` da biblioteca `rsample`.

```{r}
set.seed(1326)
df_split <- df %>%
  initial_split(prop = .75, strata = sex)

df_split
```

- Os conjuntos de treinamento e de teste são obtidos através das funções `training()` e `testing()`, respectivamente.

```{r}
trn_df <- df_split %>%
  training()

tst_df <- df_split %>%
  testing()
```

## Particionamento de dados:`rsample` {.smaller}

- Com o conjunto de treinamento vamos gerar partições para um processo de validação cruzada com 5 `folds`, utilizando a função `vfold_cv()`.

```{r}
set.seed(1326)
df_cv <- trn_df %>%
  vfold_cv(v = 5, strata = sex)

df_cv
```

## Análise exploratória de dados {.smaller}

- Explore o conjunto de treinamento por conta própria!
  - Explore a distribuição da variável alvo, `sex`;
  - Verifique como se distribuem as variáveis numéricas;
  - Como a variável alvo, `sex`, se relaciona com a variável `species`?
  - Como a distribuição das variáveis numéricas difere entre as classes da variável alvo?
  
## Análise exploratória de dados {.smaller}

```{r}
trn_df %>%
  ggplot(aes(x = sex)) +
  geom_bar()
```

## Análise exploratória de dados {.smaller}

```{r}
trn_df %>%
  ggplot(aes(x = sex, fill = species)) +
  geom_bar()
```

## Análise exploratória de dados {.smaller}

```{r}
trn_df %>%
  ggplot(aes(x = sex, fill = island)) +
  geom_bar()
```

## Análise exploratória de dados {.smaller}

```{r}
trn_df %>%
  ggplot(aes(x = bill_length_mm, fill = sex, color = sex)) +
  geom_density(alpha = .7)
```

## Análise exploratória de dados {.smaller}

```{r}
trn_df %>%
  ggplot(aes(x = bill_depth_mm, fill = sex, color = sex)) +
  geom_density(alpha = .7)
```

## Análise exploratória de dados {.smaller}

```{r}
trn_df %>%
  ggplot(aes(x = flipper_length_mm, fill = sex, color = sex)) +
  geom_density(alpha = .7)
```

## Análise exploratória de dados {.smaller}

```{r}
trn_df %>%
  ggplot(aes(x = body_mass_g, fill = sex, color = sex)) +
  geom_density(alpha = .7)
```

## Análise exploratória de dados {.smaller}

```{r}
trn_df %>%
  ggplot(aes(flipper_length_mm, bill_length_mm, color = sex, size = body_mass_g)) +
  geom_point(alpha = 0.5)
```

## Análise exploratória de dados {.smaller}

```{r}
trn_df %>%
  ggplot(aes(flipper_length_mm, bill_length_mm, color = sex, size = body_mass_g)) +
  geom_point(alpha = 0.5) +
  facet_wrap(~species)
```

## O que constitui um modelo: `parsnip` {.smaller}

- Como você ajustaria um modelo linear em `R`?

- Existem diversas maneiras de fazer isso, certo?

- Por exemplo:
  - `lm` para o modelo de regressão linear clássico;
  - `glm` para modelos lineares generalizados;
  - `glmnet` para regressão linear com regularização;
  - `gls` para modelos lineares por mínimos quadrados generalizados;
  - `keras` para regressão usando TensorFlow;
  - `spark` para *big data*;
  - `brulee` para regressão usando torch
  
## O que constitui um modelo: `parsnip` {.smaller}

- Em `R`, existem diversas funções para o mesmo fim;

- Essas funções, na maioria das vezes, possuem diferentes interfaces e recebem diferentes argumentos;

- A biblioteca `parsnip` se propõe a resolver esse problema oferecendo uma interface padronizada.

![](parsnip.jpeg){fig-align='center'}

## O que constitui um modelo: `parsnip` {.smaller}

- Para especificar um modelo com `parsnip`:
  - Escolha um modelo (*model*);
  - Especifique um motor computacional (*engine*);
  - Defina o modo (*mode*).
  
### O que é cada parte dessas?

- *model*: o tipo de modelo a ser utilizado. Por exemplo: regressão logística, redes neurais, floresta aleatória, etc.;

- *engine*: a biblioteca a partir da qual *model* deve ser ajustado. Por exemplo: `glmnet`, `nnet`, `ranger`, etc.;

- *mode*: especifica o tipo de tarefa: classificação (*classification*), regressão (*regression*) ou regressão para dados com censura (*censored regression*).
  

## O que constitui um modelo: `parsnip` {.smaller}

- Escolha um modelo (*model*):
```{r}
rand_forest()
```

- Especifique um motor (*engine*):
```{r}
rand_forest() %>%
  set_engine("randomForest")
```

- Defina o modo:
```{r}
rand_forest() %>%
  set_engine("randomForest") %>%
  set_mode("classification")
```

## O que constitui um modelo: `parsnip` {.smaller}

::: {.r-fit-text}

<br>

<br>

<br>

<br>

Todos os modelos disponíveis estão listados em: [https://www.tidymodels.org/find/parsnip/](https://www.tidymodels.org/find/parsnip/)
:::

## O que constitui um modelo: `parsnip` {.smaller}

![](parsnip_models.jpeg){fig-align='center'}

<!-- ## O que constitui um modelo: `parsnip` {.smaller} -->

<!-- - Vamos definir alguns modelos que usaremos a seguir. -->
<!-- ```{r} -->
<!-- tree_spec <- decision_tree() %>% -->
<!--   set_engine("rpart") %>% -->
<!--   set_mode("classification") -->

<!-- knn_spec <- nearest_neighbor() %>% -->
<!--   set_engine("kknn") %>% -->
<!--   set_mode("classification") -->

<!-- rf_spec <- rand_forest() %>% -->
<!--   set_engine("ranger") %>% -->
<!--   set_mode("classification") -->

<!-- log_spec <- logistic_reg() %>% -->
<!--   set_engine("glm") %>% -->
<!--   set_mode("classification") -->

<!-- svm_spec <- svm_rbf() %>% -->
<!--   set_engine("kernlab") %>% -->
<!--   set_mode("classification") -->
<!-- ``` -->

## Fluxo de trabalho: `workflows` {.smaller}

- Por que usar `workflows`?
  - `workflows` lida melhor com novos dados do que funções de `R` base em termos de novos níveis de fatores;
  - Pode ser usado em conjunto com outras ferramentas, como ferramentas de pré-processamento;
  - Ajuda na organização quando estamos trabalhando com múltiplos modelos;
  - `workflows` captura o processo de modelagem inteiro através das funções `fit()` e `predict()`.

## Fluxo de trabalho: `workflows` {.smaller .scrollable}
```{r}
tree_spec <- decision_tree() %>%
  set_engine("rpart") %>%
  set_mode("classification")

tree_spec %>%
  fit(sex ~ bill_length_mm+bill_depth_mm+flipper_length_mm+body_mass_g, data = trn_df)
```

## Fluxo de trabalho: `workflows` {.smaller .scrollable}
```{r}
workflow() %>%
  add_formula(sex ~ bill_length_mm+bill_depth_mm+flipper_length_mm+body_mass_g) %>%
  add_model(tree_spec) %>%
  fit(data = trn_df)
```

## Fluxo de trabalho: `workflows` {.smaller .scrollable}
```{r}
tree_fit <- workflow() %>%
  add_formula(sex ~ bill_length_mm+bill_depth_mm+flipper_length_mm+body_mass_g) %>%
  add_model(tree_spec) %>%
  fit(data = trn_df)

tree_fit
```

## Fluxo de trabalho: `workflows` {.smaller .scrollable}
```{r}
predict(tree_fit, new_data = tst_df)
```

## Fluxo de trabalho: `workflows` {.smaller .scrollable}
```{r}
tree_fit %>% augment(new_data = tst_df)
```

```{r}
tree_predictions <- tree_fit %>% augment(new_data = tst_df)
tree_predictions$.pred_class
```

## Fluxo de trabalho: `workflows` {.smaller .scrollable}
```{r}
library(rpart.plot)
tree_fit %>%
  extract_fit_engine() %>%
  rpart.plot(roundint = FALSE)
```

## Avaliação de modelos: `yardstick` {.smaller}

- Como avaliamos se um modelo tem bom desempenho?

- A biblioteca `yardstick` sornece funções para calcular diversas métricas de avaliação.

```{r}
tree_fit %>%
  augment(new_data = tst_df) %>%
  conf_mat(truth = sex, estimate = .pred_class)
```

```{r}
tree_fit %>%
  augment(new_data = tst_df) %>%
  metrics(truth = sex, estimate = .pred_class)
```

## Avaliação de modelos: `yardstick` {.smaller}
```{r}
tree_fit %>%
  augment(new_data = tst_df) %>%
  conf_mat(truth = sex, estimate = .pred_class) %>%
  autoplot(type = "heatmap")
```

## Avaliação de modelos: `yardstick` {.smaller}
```{r}
tree_fit %>%
  augment(new_data = tst_df) %>%
  accuracy(truth = sex, estimate = .pred_class)
```

```{r}
tree_fit %>%
  augment(new_data = tst_df) %>%
  sensitivity(truth = sex, estimate = .pred_class)
```

```{r}
tree_fit %>%
  augment(new_data = tst_df) %>%
  specificity(truth = sex, estimate = .pred_class)
```
## Avaliação de modelos: `yardstick` {.smaller .scrollable}
```{r}
penguins_metrics <- metric_set(accuracy, specificity, sensitivity, precision)

tree_fit %>%
  augment(new_data = tst_df) %>%
  penguins_metrics(truth = sex, estimate = .pred_class)
```

```{r}
tree_fit %>%
  augment(new_data = tst_df) %>%
  group_by(species) %>%
  penguins_metrics(truth = sex, estimate = .pred_class)
```

## Avaliação de modelos: `yardstick` {.smaller}
```{r}
tree_fit %>%
  augment(new_data = tst_df) %>%
  roc_curve(truth = sex, .pred_female)
```

```{r}
tree_fit %>%
  augment(new_data = tst_df) %>%
  roc_auc(truth = sex, .pred_female)
```

## Avaliação de modelos: `yardstick` {.smaller}
```{r}
tree_fit %>%
  augment(new_data = tst_df) %>%
  roc_curve(truth = sex, .pred_female) %>%
  autoplot()
```

## Avaliação de modelos: `yardstick` {.smaller}

- Vamos agora, avaliar o desempenho do modelo de árvore utilizando validação cruzada.
```{r}
tree_cv <- workflow() %>%
  add_formula(sex ~ bill_length_mm+bill_depth_mm+flipper_length_mm+body_mass_g) %>%
  add_model(tree_spec) %>%
  fit_resamples(df_cv)
```

- Vejamos:
```{r}
tree_cv %>% collect_metrics()
```



## Pré-processamento e feature engineering: `recipes` {.smaller}

- Podemos querer modificar nossas variáveis por diversas razões:
  - O modelo requer que uma ou mais variáveis estejam em um formato específico (por exemplo, variáveis *dummy* para regressão linear);
  - O modelo precisa que os dados tenham certas características (por exemplo, mesma escala para o $K$-NN);
  - A saída é melhor predita quando uma ou mais colunas são transformadas de alguma forma (também conhecido por "engenharia de atributos" ou "*feature engineering*").
    - Interações;
    - Expansões polinomiais;
    - Componentes principais;
    - Dentre outras.

## Pré-processamento e feature engineering: `recipes` {.smaller}

- A biblioteca `recipes` possui diversas funções para pré-processamento e *feature engineering*;

- Uma "receita" é uma descrição de passos a serem executados em um conjunto de dados com o objetivo de prepará-lo para a análise.

```{r}
#| eval: false
recipe(y ~ x1 + x2, data = df) %>%
  step_*() %>%
  step_*() ...
```

- Na receita, precisamos especificar a relação entre a variável de saída e as variáveis preditoras (uma fórmula) e o conjunto de dados;

- Os passos são definidos pelos `step_*()`, onde `*` especifica a transformação desejada.

## Pré-processamento e feature engineering: `recipes` {.smaller}
```{r}
penguins_rec <- recipe(sex ~ ., data = trn_df)

penguins_rec %>% summary()
```

- Esta receita apenas define os papeis de cada variável na análise.

## Pré-processamento e feature engineering: `recipes` {.smaller}

- `step_dummy()`: cria variáveis *dummy* para preditores definidos como fatores;

- `step_normalize()`: realiza padronização de variáveis preditoras;

- `step_zv()`: elimina preditores com variância zero;

- `step_corr()`: útil para lidar com preditores altamente correlacionados, encontrando o conjunto de preditores cujas correlações são menores do que um limiar;

- `step_pca()`: extração de componentes principais;

- Muito mais em: [https://www.tidymodels.org/find/recipes/](https://www.tidymodels.org/find/recipes/).

## Pré-processamento e feature engineering: `recipes` {.smaller}
```{r}
penguins_rec <- recipe(sex ~ ., data = trn_df) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_corr(all_numeric_predictors(), threshold = 0.9) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_poly(body_mass_g, degree = 2)
```

- `prep()`: estima os parâmetros dos passos definidos na receita para o conjunto de treinamento. Podemos aplicar esses passos a um outro conjunto de interesse, tipicamente, o conjunto de teste;

- `juice()`: aplica os passos definidos na receita ao conjunto de dados de interesse.

```{r}
prepped_df <- penguins_rec %>%
  prep() %>%
  juice()
```

## Pré-processamento e feature engineering: `recipes` {.smaller}
```{r}
prepped_df
```

- Ao usarmos `workflows`, no entanto, não há a necessidade de "extrair" com `prep()` e `juice()` os dados transformados pela receita, pois isso será feito implicitamente.

## Pré-processamento e feature engineering: `recipes` {.smaller}
```{r}
set.seed(1326)

lr_spec <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

lr_wflow <- workflow() %>%
  add_recipe(penguins_rec) %>%
  add_model(lr_spec)

lr_fit <- lr_wflow %>%
  fit(data = trn_df)
```

## Pré-processamento e feature engineering: `recipes` {.smaller}
```{r}
lr_fit
```

## Pré-processamento e feature engineering: `recipes` {.smaller}
```{r}
#| warning: false
#| message: false
lr_fit %>% tidy(conf.int = TRUE)
```

## Pré-processamento e feature engineering: `recipes` {.smaller .nostretch}

:::: {.columns}

::: {.column width="50%"}

<br>

<br>

<br>

> "Eu tava pensando nas receitas que eu vou fazer quando eu voltar pro Brasil"
:::

::: {.column width="50%"}
![](rebeca_recipes.jpeg){fig-align='center' width="75%"}
:::

::::

## Otimização de hiperparâmetros: `tune` {.smaller}

- Algumas quantidades relacionadas aos modelos ou algoritmos não podem ser estimadas diretamente dos dados: hiperparâmetros;

- Alguns exemplos:
  - Profundidade da árvore em árvores de decisão;
  - Número de vizinhos no $K$-NN;
  - Funções de ativação em redes neurais.
  
- A ideia é testar diferentes valores para os hiperparâmetros e medir o desempenho dos modelos;

- Uma vez que os hiperparâmetros ótimos são determinados, os modelos podem ser finalizados sendo ajustados no conjunto de treinamento completo.

## Otimização de hiperparâmetros: `tune` {.smaller}

- Com a biblioteca `tidymodels`, podemos apenas marcar na especificação dos modelos com a função `tune()` quais hiperparâmetros desejamos que sejam otimizados;

- Curiosamente, a função `tune()` retorna... ela mesma!
```{r}
tune()

str(tune())

tune("Espero que estejam gostando deste minicurso!")
```

## Otimização de hiperparâmetros: `tune` {.smaller}

- Vamos utilizar um modelo de Floresta Aleatória para ilustrar o processo de otimização de hiperparâmetros.

- Este modelo possui três hiperparâmetros a serem otimizados:
  - `mtry`: número de preditores selecionados aleatoriamente para definição dos nós;
  - `trees`: número de árvores;
  - `min_n`: tamanho mínimo dos nós.
  
## Otimização de hiperparâmetros: `tune` {.smaller}
```{r}
rf_spec <- rand_forest(mtry = tune(), trees = tune(), min_n = tune()) %>%
  set_engine("ranger") %>%
  set_mode("classification")

rf_spec %>% translate()
```

## Otimização de hiperparâmetros: `tune` {.smaller}
```{r}
rf_wflow <- workflow() %>%
  add_recipe(penguins_rec) %>%
  add_model(rf_spec)
```

```{r}
rf_wflow %>% extract_parameter_set_dials()
```

```{r}
rf_param <- rf_wflow %>%
  extract_parameter_set_dials() %>%
  update(mtry = mtry(c(2L,5L)))

rf_param
```

## Otimização de hiperparâmetros: `tune` {.smaller}

```{r}
ctrl <- control_grid(save_pred = TRUE)

rf_res <- rf_wflow %>%
  tune_grid(
    resamples = df_cv,
    grid = 25,
    param_info = rf_param,
    control = ctrl,
    metrics = penguins_metrics
  )

rf_res
```


## Otimização de hiperparâmetros: `tune` {.smaller}
```{r}
autoplot(rf_res)
```

## Otimização de hiperparâmetros: `tune` {.smaller}
```{r}
collect_metrics(rf_res)
```

```{r}
show_best(rf_res, metric = "accuracy")
```

## Otimização de hiperparâmetros: `tune` {.smaller}

- A função `select_best()` seleciona o melhor conjunto de hiperparâmetros de acordo com uma métrica pré-estabelecida.
```{r}
best_acc <- rf_res %>%
  select_best(metric = "accuracy")

best_acc
```

## Otimização de hiperparâmetros: `tune` {.smaller}

- Usando a função `last_fit()` ajustamos o modelo final no conjunto de treinamento completo considerando o melhor conjunto de hiperparâmetros selecionado na etapa de validação cruzada.
```{r}
final_res <- rf_wflow %>%
  finalize_workflow(best_acc) %>%
  last_fit(df_split)
```


- E avaliamos no conjunto de teste.
```{r}
final_res %>% collect_metrics()
```

## Otimização de hiperparâmetros: `tune` {.smaller}

```{r}
final_res %>%
  extract_fit_parsnip()
```

## Otimização de hiperparâmetros: `tune` {.smaller}

```{r}
final_res %>%
  augment() %>%
  conf_mat(truth = sex, estimate = .pred_class) %>%
  autoplot(type = "heatmap")
```

## Otimização de hiperparâmetros: `tune` {.smaller}

```{r}
final_res %>%
  augment() %>%
  roc_curve(truth = sex, .pred_female) %>%
  autoplot()
```

## Otimização de hiperparâmetros: *racing* {.smaller}

- Relembrando, a ideia de *racing* é tornar o processo de *grid search* mais rápido.
```{r}
#| warning: false
#| message: false
library(finetune)

ctrl <- control_race(save_pred = TRUE)

set.seed(1326)
rf_race_res <- rf_wflow %>%
  tune_race_anova(
    resamples = df_cv,
    grid = 25,
    param_info = rf_param,
    control = ctrl,
    metrics = penguins_metrics
  )

rf_race_res
```

## Otimização de hiperparâmetros: *racing* {.smaller}
```{r}
autoplot(rf_race_res)
```


## Otimização de hiperparâmetros: *racing* {.smaller}
```{r}
best_acc <- rf_race_res %>%
  select_best(metric = "accuracy")

best_acc
```

```{r}
final_res <- rf_wflow %>%
  finalize_workflow(best_acc) %>%
  last_fit(df_split)
```

```{r}
final_res %>% collect_metrics()
```

## Otimização de hiperparâmetros: *racing* {.smaller}
```{r}
final_res %>%
  augment() %>%
  conf_mat(truth = sex, estimate = .pred_class) %>%
  autoplot(type = "heatmap")
```

## Otimização de hiperparâmetros: *racing* {.smaller}

```{r}
final_res %>%
  augment() %>%
  roc_curve(truth = sex, .pred_female) %>%
  autoplot()
```

## Avaliando muitos modelos: `workflowsets` {.smaller}

- Em diversas situações, queremos comparar vários modelos e, ajustar um a um, torna o processo muito trabalhoso.

- A função `workflow_set()` da biblioteca `workflowsets` gera uma conjunto de workflows.

- Considere que desejamos comparar três modelos: regressão logística regularizada, árvore de decisão e floresta aleatória.

```{r}
rl_spec
```


## Fim {.smaller}

![](fim.jpeg){fig-align=center}

## Obrigado pela Atenção! {.title-slide .whiteslide}

<center>Marcelo Rodrigo Portela Ferreira</center>

<center>[marcelorpf@gmail.com](marcelorpf@gmail.com)</center>

![](logo.jpeg){fig-align='center'}

<center>Material disponível em: [http://www.de.ufpb.br/~marcelo](http://www.de.ufpb.br/~marcelo)</center>
