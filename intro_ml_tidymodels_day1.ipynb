{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Introdução à Aprendizagem de Máquina com Tidymodels\"\n",
        "subtitle: \"<br>XV Semana de Estatística - UFES, Vitória/ES <br> 7 a 8 de novembro de 2024\"\n",
        "author: \"Prof. Marcelo R. P. Ferreira\"\n",
        "institute: \"DE/UFPB -- PPGMDS/UFPB\"\n",
        "format:\n",
        "  revealjs:\n",
        "    theme: beige\n",
        "    transition: slide\n",
        "    footer: \"Introdução à Aprendizagem de Máquina com Tidymodels - [Prof. Marcelo R. P. Ferreira](http://www.de.ufpb.br/~marcelo)\"\n",
        "    slide-number: true\n",
        "    show-slide-number: all\n",
        "    embed-resources: true\n",
        "    include-in-header:\n",
        "      text: |\n",
        "        <style>\n",
        "        #title-slide .title {\n",
        "          font-size: 2.5em;\n",
        "          color: #b22222;\n",
        "        }\n",
        "        .caption {\n",
        "          text-align: center;\n",
        "        }\n",
        "        </style>\n",
        "---"
      ],
      "id": "1013a42e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quem sou eu? {.smaller}\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"40%\"}\n",
        "![](eu.png){fig.align=center}\n",
        ":::\n",
        "\n",
        "::: {.column width=\"60%\"}\n",
        "- Na maior parte do tempo eu sou pai de duas meninas, professor, cientista e cervejeiro caseiro.\n",
        "- Faço parte do [Departamento de Estatística](https://www.ufpb.br/de) da [UFPB](https://www.ufpb.br) desde dezembro de 2008 e do [Programa de Pós-graduação em Modelos de Decisão e Saúde](https://sigaa.ufpb.br/sigaa/public/programa/portal.jsf?id=1895) (PPGMDS/UFPB) desde novembro de 2022.\n",
        "- Formação acadêmica:\n",
        "  - Graduação em Estatística pela UFPE;\n",
        "  - Mestrado em Estatística pela UFPE;\n",
        "  - Doutorado em Ciência da Computação pela UFPE;\n",
        "  - Pós-doutorado em Aprendizagem de Máquina na RWTH Aachen University, Alemanha.\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "## Quem são vocês? {.smaller}\n",
        "\n",
        "- Possui conhecimento básico sobre a linguagem `R`.\n",
        "\n",
        "- Tem alguma familiaridade com o dialeto `tidyverse` e com o uso de *pipe* (`%>%` ou `|>`).\n",
        "\n",
        "- Compreende conceitos básicos de estatística.\n",
        "\n",
        "- Não necessariamente é um especialista (ou mesmo um intermediário) em modelagem estatística ou aprendizagem de máquina.\n",
        "\n",
        "## Qual é o nosso plano? {.smaller}\n",
        "\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "**Dia 1**:\n",
        "\n",
        "- Aprendizagem de máquina\n",
        "  - Conceitos básicos;\n",
        "  - Tipos de Aprendizagem de Máquina;\n",
        "  - Dados estruturados e não-estruturados;\n",
        "  - Pré-processamanto de dados;\n",
        "  - Avaliação de modelos;\n",
        "  - Particionamento de dados:\n",
        "    - *Holdout* e $K$-*fold cross-validation*;\n",
        "  - Otimização de hiperparâmetros:\n",
        "    - *Grid search* e *Grid search* via *racing*.\n",
        ":::\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "**Dia 2**:\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "# Conceitos básicos em Aprendizagem de Máquina\n",
        "\n",
        "## Aprendizagem de Máquina {.smaller}\n",
        "\n",
        "- Aprendizagem de Máquina (AM) ou *Machine Learning* (*ML*) é uma subárea da Inteligência Artificial que estuda modelos e algoritmos de aprendizado a partir de dados.\n",
        "\n",
        "- Os modelos ou algoritmos são determinados pelo tipo de dado que se tem disponível e pelo tipo de tarefa a ser executada.\n",
        "\n",
        "- Esses modelos são automatizados de modo a melhorarem o processo de aprendizagem com base em suas experiências, sem a necessidade de serem reprogramados (ou seja, sem qualquer assistência humana).\n",
        "\n",
        "- O produto dos modelos ou algoritmos são coeficientes, pesos ou regras e o processo de aprendizagem se dá pela atualização dessas características a partir de novas experiências (novos dados).\n",
        "\n",
        "- Originalmente, os métodos de AM eram de cunho estritamente computacional. Mas, a partir do final dos anos 90, passaram a ter muitas inserseções com a estatística.\n",
        "\n",
        "## Aprendizagem de Máquina {.smaller}\n",
        "\n",
        "![O que é aprendizagem de máquina? Créditos da imagem: [https://vas3k.com/blog/machine_learning/](https://vas3k.com/blog/machine_learning/)](ml.jpeg)\n",
        "\n",
        "## Mas, o que é aprender? {.smaller}\n",
        "\n",
        "- Ganhar conhecimento através do estudo, experiência ou sendo ensinado;\n",
        "\n",
        "- Aprendizagem X Aprendizado\n",
        "  - Aprendizagem: é o processo pelo qual se adquire o conhecimento $\\rightarrow$ algoritmos;\n",
        "  - Aprendizado é o conhecimento adquirido $\\rightarrow$ modelos;\n",
        "  \n",
        " - Em Aprendizagem de Máquina, focamos no estudo de algoritmos para adquirir descrições estruturais (modelos) sobre exemplos de dados;\n",
        " \n",
        " - Os algoritmos da Aprendizagem de Máquina permitem que escrevamos programas cujo desempenho tende a melhorar à medida que \"ganham experiência\";\n",
        " \n",
        " - Essa experiência corresponde aos dados que são fornecidos ao programa;\n",
        " \n",
        " - Os algoritmos buscam extrair hipóteses dos dados.\n",
        " \n",
        "## Tarefa, Medida e Experiência {.smaller}\n",
        " \n",
        "- De uma maneira geral, o uso da Aprendizagem de Máquina para solucionar uma tarefa envolve:\n",
        "  - Otimizar a realização de uma tarefa $T$;\n",
        "  - Em relação a uma medida de desempenho $P$;\n",
        "  - Com base na experiência $E$;\n",
        "  \n",
        "- Exemplo:\n",
        "\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"35%\"}\n",
        "![Base de dados `mnist`](mnist.png){fig-align='center'}\n",
        ":::\n",
        "\n",
        "::: {.column width=\"65%\"}\n",
        "- Tarefa: reconhecer e classificar caracteres manuscritos;\n",
        "- Medida: porcentagem de caracteres classificados corretamente;\n",
        "- Experiência: base de dados de caracteres manuscritos com a respectiva classificação.\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "## Tipos de Aprendizagem de Máquina {.smaller}\n",
        "\n",
        "![Aprendizagem de Máquina Clássica. Créditos da imagem: [https://vas3k.com/blog/machine_learning/](https://vas3k.com/blog/machine_learning/)](classical_ml.jpeg){fig-align='center'}\n",
        "\n",
        "## Tipos de Aprendizagem de Máquina {.smaller}\n",
        "\n",
        "![Visão mais ampla da Aprendizagem de Máquina. Créditos da imagem: [https://vas3k.com/blog/machine_learning/](https://vas3k.com/blog/machine_learning/)](wider_ml_definition.jpeg){fig-align='center'}\n",
        "\n",
        "## Tipos de Aprendizagem de Máquina {.smaller}\n",
        "\n",
        "- Aprendizagem supervisionada:\n",
        "  - O algoritmo de aprendizagem recebe um conjunto de exemplos de treinamento em que um rótulo alvo é conhecido;\n",
        "  - Cada exemplo é descrito por um vetor de valores (variáveis) e pelo rótulo (classe ou valor alvo) associado ;\n",
        "  - Inclui tarefas de classificação ($\\hat{y} = \\textrm{arg}\\max_y P(Y=y|X=\\mathbf{x})$) e de regressão ($\\hat{y} = \\mathbb{E}[Y|X=\\mathbf{x}]$);\n",
        "  \n",
        "![Classificação X Regressão](regxclass.jpg){fig-align='center'}\n",
        "\n",
        "## Tipos de Aprendizagem de Máquina {.smaller}\n",
        "\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "- Exemplos de métodos supervisionados para a tarefa de classificação:\n",
        "  - Regressão Logística;\n",
        "  - $K$-NN;\n",
        "  - Redes Neurais Artificiais;\n",
        "  - Árvores de Classificação;\n",
        "  - *Support Vector Machines*;\n",
        "  - *Extreme Gradient Boosting*;\n",
        "  - *Random Forests*.\n",
        ":::\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "- Exemplos de métodos supervisionados para a tarefa de regressão:\n",
        "  - Regressão Linear Múltipla;\n",
        "  - $K$-NN;\n",
        "  - Redes Neurais Artificiais;\n",
        "  - Árvores de Regressão;\n",
        "  - *Support Vector Machines*;\n",
        "  - *Extreme Gradient Boosting*;\n",
        "  - *Random Forests*.\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "## Tipos de Aprendizagem de Máquina {.smaller}\n",
        "\n",
        "- Aprendizagem não-supervisionada:\n",
        "  - O indutor analisa os exemplos fornecidos e tenta determinar se existem padrões previamente desconhecidos nos dados;\n",
        "  - Comumente, o objetivo é encontrar $P(X)$, ou seja, a distribuição de probabilidade de $X$;\n",
        "  - Tarefas não-supervisionadas incluem: agrupamento, redução da dimensionalidade, detecção de anomalias e regras de associação;\n",
        "  \n",
        "![Ilustração da tarefa de agrupamento](agrupamento.jpg){fig-align='center'}\n",
        "\n",
        "## Tipos de Aprendizagem de Máquina {.smaller}\n",
        "\n",
        "- Aprendizagem por reforço:\n",
        "  - Envolve situações em que um ou mais agentes aprendem por tentativa e erro ao atuar sobre um ambiente dinâmico;\n",
        "  - Não há uma fonte externa de exemplos. Há apenas a própria experiência do agente;\n",
        "  - É necessário definir que ações o agente pode desempenhar e qual é a medida de desempenho.\n",
        "\n",
        "![Exemplo de um sistema de aprendizado por reforço](chrome.png){fig-align='center'}\n",
        "\n",
        "## As duas culturas: Modelos X Algoritmos {.smaller}\n",
        "\n",
        "- A verdadeira \"caixa-preta\".\n",
        "\n",
        "![](blackbox.jpeg){fig-align='center'}\n",
        "\n",
        "## As duas culturas: Modelos X Algoritmos {.smaller}\n",
        "\n",
        "- Vamos assumir que a estimação será feita com base em $S$, uma amostra i.i.d. da distribuição conjunta de $(\\mathbf{X},Y)$;\n",
        "\n",
        "- $S$ é comumente chamada de amostra de treinamento.\n",
        "\n",
        "![](estimacao.jpeg){fig-align='center'}\n",
        "\n",
        "## As duas culturas: Modelos X Algoritmos {.smaller}\n",
        "\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "- *Data modeling culture*: Abordagem da modelagem estatística clássica.\n",
        "\n",
        "![](est_estoc.jpeg){fig-align='center'}\n",
        "\n",
        "- Exemplo:\n",
        "\n",
        "$$\n",
        "y_i=\\beta_0+\\beta_1x_{1i}+\\cdots+\\beta_px_{pi}+\\varepsilon_i,\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\varepsilon_i\\sim N(0,\\sigma^2),\\quad i=1,\\ldots,n.\n",
        "$$\n",
        "\n",
        ":::\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "- *Algorithm modeling culture*: Aprendizagem de máquina.\n",
        "\n",
        "![](est_desc.jpeg){fig-align='center'}\n",
        "\n",
        "- Exemplo:\n",
        "\n",
        "$$\n",
        "y_i=f(\\mathbf{x}_i) + \\varepsilon_i,\\quad i=1,\\ldots,n.\n",
        "$$\n",
        "\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "## As duas culturas: Modelos X Algoritmos {.smaller .nostretch}\n",
        "\n",
        "<br>\n",
        "\n",
        "<br>\n",
        "\n",
        "![](caixapreta.jpeg){fig-align='center' width=\"60%\"}\n",
        "\n",
        "# Os benditos dados...\n",
        "\n",
        "## Dados tabulares ou estruturados {.smaller}\n",
        "\n",
        "- Atributos/Variáveis podem ser físicos ou abstratos, como sintomas;\n",
        "- Cada exemplo/observação é descrito por um conjunto de variáveis de entrada ou vetor de características;\n",
        "- Cada exemplo corresponde a uma ocorrência/observação;\n",
        "- Os atributos estão associados a propriedades das observações;\n",
        "- Os dados que usamos para treinar nossos modelos são agregados em um **conjunto ou base de dados** (*data set* ou *dataset*);\n",
        "- O conjunto de dados costuma ser representado por uma matriz $\\mathbf{X}_{n \\times p}$\n",
        "  - $n$ é o número de instâncias;\n",
        "  - $p$ é o número de atributos de cada observação e define a dimensionalidade do espaço do problema.\n",
        "  \n",
        "## Dados tabulares ou estruturados {.smaller}\n",
        "\n",
        "![](dados.png){fig-width='center'}\n",
        "\n",
        "- Este conjunto aparentemente tem $p=10$ variáveis;\n",
        "\n",
        "- No entanto, a primeira e a segunda são apenas identificadores de paciente;\n",
        "\n",
        "- E a última, que indica o diagnóstico, possivelmente será selecionada como alvo em uma tarefa de classificação, sendo tratada como uma variável separada, digamos, $Y$;\n",
        "\n",
        "- Portanto, $p=7$.\n",
        "\n",
        "## Dados não-estruturados {.smaller}\n",
        "\n",
        "- Dados não-estruturados representam múltiplos tipos de dados que não podem ser facilmente analisados ou categorizados;\n",
        "\n",
        "- Usulalmente são armazenados em formatos nativos;\n",
        "\n",
        "- Não podem ser organizados em linhas e colunas;\n",
        "\n",
        "- Imagens, áudio, video, arquivos de texto, postagens em redes sociais, mensagens em aplicativos de comunicação, etc.;\n",
        "\n",
        "- Requerem, em geral, mais espaço de armazenamento;\n",
        "\n",
        "- Estimado em torno de 80% dos dados das empresas.\n",
        "\n",
        "# Pré-processamento de dados tabulares\n",
        "\n",
        "## Pré-processamento de dados tabulares {.smaller}\n",
        "\n",
        "- Antes de alimentar um algoritmo de aprendizagem de máquina com o conjunto de dados observados, comumente precisamos realizar diversas atividades de preparação dos dados, incluindo:\n",
        "  - Eliminação manual de atributos;\n",
        "  - Integração de dados;\n",
        "  - Amostragem;\n",
        "  - Balanceamento;\n",
        "  - Limpeza;\n",
        "  - Redução de dimensionalidade;\n",
        "  - Transformação.\n",
        "\n",
        "## Pré-processamento de dados tabulares {.smaller}\n",
        "\n",
        "- O objetivo é melhorar a qualidade dos dados, i.e., tornar mais fácil o ajuste de modelos;\n",
        "\n",
        "- Minimizam problemas de ruídos, anomalias/outliers, valores/rótulos incorretos, duplicados ou ausentes;\n",
        "\n",
        "- Também podem adequar os dados para uso de determinados algoritmos, e.g. algoritmos com entradas exclusivamente numéricas.\n",
        "\n",
        "![](iceberg.jpeg){fig-align='center'}\n",
        "\n",
        "## Eliminação manual de atributos {.smaller}\n",
        "\n",
        "- Removemos atributos que não contribuem para a construção dos modelos;\n",
        "- Nesse momento, o conhecimento e a experiência dos especialistas são fundamentais.\n",
        "\n",
        "![](hospital-id.png){fig.align='center'}\n",
        "\n",
        "## Integração de dados {.smaller}\n",
        "\n",
        "- Essa atividade trata da junção de duas ou mais bases de dados que possuem informações sobre as mesmas observações;\n",
        "\n",
        "- Devemos buscar atributos comuns nos conjuntos que serão combinados;\n",
        "  - Exemplos: CPF, CNPJ e identificadores de uma maneira geral, além de outros atributos que podem estar repetidos;\n",
        "\n",
        "- Atributos cruzados devem ter um valor único para cada observação.\n",
        "\n",
        "## Amostragem de dados {.smaller}\n",
        "\n",
        "- Alguns algoritmos de aprendizagem de máquina podem ter dificuldade de lidar com grandes volumes de dados;\n",
        "\n",
        "- Assim, torna-se útil obter uma amostra **representativa** dos dados para treinar o modelo;\n",
        "  - Os dados da amostra devem seguir a mesma distribuição dos dados originais (qual?);\n",
        "  \n",
        "- Diferentes amostras podem gerar modelos diferentes.\n",
        "\n",
        "## Balanceamento de dados {.smaller}\n",
        "\n",
        "- Em certas aplicações (como na medicina), é comum que uma classe seja muito mais frequente do que outra;\n",
        "\n",
        "- Nesses casos, o modelo de AM pode aprender a \"chutar\" sempre a classe mais frequente;\n",
        "\n",
        "- Soluções:\n",
        "  - Equalizar os tamanhos das classes\n",
        "    - Subamostragen (*Undersampling*);\n",
        "    - Sobreamostragem (*Oversampling*);\n",
        "    - SMOTE (*Synthetic Minority Oversampling Technique*);\n",
        "  - Classificação baseada em custos;\n",
        "  - Ajustar um modelo por classe.\n",
        "\n",
        "## Balanceamento de dados {.smaller}\n",
        "\n",
        "![Ilustração de Undersampling e Oversampling](over-under-sampling.png){fig-align='center' width=\"65%\"}\n",
        "\n",
        "![Ilustração do método SMOTE](smote.png){fig-align='center' width=\"65%\"}\n",
        "\n",
        "## Limpeza dos dados {.smaller}\n",
        "\n",
        "- Remove problemas relacionados à qualidade dos dados;\n",
        "\n",
        "- Dados ruidosos: erros de registro, variações de qualidade de sinal.\n",
        "  - Diferente de outliers;\n",
        "  \n",
        "- Inconsistentes: contradizem valores de outros atributos do mesmo objeto;\n",
        "\n",
        "- Redundantes: dois ou mais objetos/atributos com os mesmos valores;\n",
        "\n",
        "- Incompletos (com ausência de valores).\n",
        "\n",
        "![](limpeza.png){fig-align='center'}\n",
        "\n",
        "## Dados incompletos {.smaller}\n",
        "\n",
        "- Possibilidades de correção:\n",
        "  - Eliminar instâncias/colunas com valores ausentes;\n",
        "  - Usar média/moda/mediana dos valores conhecidos;\n",
        "  - Criar um novo valor que indique o atributo tem valor faltante;\n",
        "  - Estimar a distribuição conjunta dos atributos para depois preencher os faltantes com os valores mais prováveis;\n",
        "  - Usar algoritmos capazes de lidar com dados ausentes.\n",
        "  \n",
        "## Dados inconsistentes {.smaller}\n",
        "\n",
        "- Problemas na anotação dos dados podem resultar em atributos de entrada que não explicam o atributo alvo/classe.\n",
        "\n",
        "![](inconsistente.png){fig-align='center'}\n",
        "\n",
        "## Dados redundantes {.smaller}\n",
        "\n",
        "- O mesmo atributo pode aparecer em dois formatos diferentes. Exemplo: idade X data de nascimento;\n",
        "\n",
        "- Atributos podem ser altamente correlacionados\n",
        "  - Não há acréscimo de informação ao manter os dois;\n",
        "  - Mantém-se apenas um;\n",
        "  - Boa parte dos algoritmos de AM assume que não há correlação entre atributos.\n",
        "  \n",
        "## *Outliers* {.smaller}\n",
        "\n",
        "- Dados que diferem bastante dos outros elementos do conjunto de dados ou de sua classe;\n",
        "\n",
        "- Podem ser retirados ou mantidos, caso deseje-se gerar modelos que modelam a sua existência;\n",
        "\n",
        "- Existem técnicas cujo objetivo é detectar outliers.\n",
        "\n",
        "## Transformação de dados {.smaller}\n",
        "\n",
        "- Frequentemente é necessário transformar os tipos ou valores dos atributos. Pode-se, por exemplo, discretizar valores numéricos ou transformá-los em intervalos;\n",
        "\n",
        "- Pode-se transformar atributos qualitativos com $k$ categorias em $k$ ou $k-1$ atributos binários: *One-hot-encoding* e Variáveis *dummy*.\n",
        "  - Se existirem muitas categorias, isso pode tornar a dimensão do muito alta. Nesse caso, pode-se usar *frequency encoding*, em que as categorias são substituídas por suas frequências;\n",
        "  \n",
        "- Quando os atributos têm escalas muito diferentes, fazemos normalização:\n",
        "\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "$$\n",
        "X_{novo} = \\frac{X - X_{min}}{X_{max} - X_{min}},\n",
        "$$\n",
        "\n",
        "Em que $X_{min}$ é o valor mínimo e $X_{max}$ é o valor máximo. Novos valores no intervalo $[0, 1]$.\n",
        ":::\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "$$\n",
        "Z = \\frac{X - \\hat{\\mu}}{\\hat{\\sigma}},\n",
        "$$\n",
        "\n",
        "Onde $\\hat{\\mu}$ é a média amostral e $\\hat{\\sigma}$ é o desvio-padrão amostral. Essa transformação lida melhor com *outliers*.\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "## Avaliação de modelos {.smaller}\n",
        "\n",
        "- Para o contexto de aprendizado supervisionado, seja $\\mathbf{X}$ um vetor de variáveis de entrada, sendo suas componentes denotadas por $X_{j}$, com $j=1,\\ldots,p$. Enquanto a variável de saída será denotada por ${Y}$;\n",
        "\n",
        "- Tipicamente $\\mathbf{X} \\in \\mathbb{R}^p = \\mathcal{X}$ e $Y \\in C = \\mathcal{Y} \\subseteq  \\mathbb{R}$, onde $C=\\{1,2,\\ldots,K\\}$ é o conjunto dos índices das classes;\n",
        "\n",
        "- Nosso interesse está na relação\n",
        "$$\n",
        "f: \\mathcal{X} \\rightarrow \\mathcal{Y}\n",
        "$$\n",
        "$$\n",
        "\\mathbf{x} \\rightarrow f(\\mathbf{x});\n",
        "$$\n",
        "\n",
        "- Seja $S = \\left\\lbrace \\left( \\mathbf{x}_{1},y_{1}\\right) \\ldots \\left( \\mathbf{x}_{n},y_{n}\\right) \\right\\rbrace$ contido em $\\mathcal{X} \\times \\mathcal{Y}$;\n",
        "\n",
        "- Desejamos encontrar a função  $\\hat{f}: \\mathcal{X} \\rightarrow \\mathcal{Y}$ usando $S$ tal que \n",
        "$$\n",
        "\\hat{f}(\\mathbf{x}) \\approx f(\\mathbf{x}),\\quad\\forall\\mathbf{x} \\in \\mathcal{X}.\n",
        "$$\n",
        "\n",
        "## Avaliação de modelos {.smaller}\n",
        "\n",
        "- Mas, como avaliamos o quão bem estamos estimando $f$?\n",
        "\n",
        "- Para a tarefa de refressão, a medida mais comumente utilizada é o erro quadrático médio (*MSE*), dado por:\n",
        "$$\n",
        "MSE=\\frac{1}{n}\\sum_{i=1}^{n}(y_i-\\hat{f}(\\mathbf{x}_i))^2;\n",
        "$$\n",
        "- Um valor pequeno para o *MSE* indica que as respostas previstas estão próximas das respostas verdadeiras;\n",
        "\n",
        "- Outras medidas que são utilizadas em tarefas de regressão são: o erro absoluto médio (*MAE*) e o erro percentual absoluto médio (*MAPE*).\n",
        "\n",
        "## Avaliação de modelos {.smaller}\n",
        "\n",
        "- Para a tarefa de classificação, a medida mais comumente utilizada é a taxa de erro de classificação ou, com interpretação em sentido oposto, a acurácia;\n",
        "\n",
        "- É comum (e útil) a construção de uma matriz conhecida por matriz de confusão;\n",
        "\n",
        "- Essa matriz é uma tabela de contingência entre as classes preditas e as classes verdadeiras (conhecidas);\n",
        "\n",
        "- Outras medidas tipicamente utilizadas são:\n",
        "  - $\\textrm{F}_1$-escore;\n",
        "  - Precisão;\n",
        "  - Especificidade;\n",
        "  - Sensibilidade (Cobertura, Revocação ou *Recall*);\n",
        "  - Curva ROC: Sensibilidade (Taxa de Verdadeiros Positivos) $\\times$ $1-$Especificidade (Taxa de Falsos Positivos);\n",
        "  - Área sob a curva ROC (AUC ou AUROC);\n",
        "  - etc.\n",
        "  \n",
        "## Avaliação de modelos {.smaller}\n",
        "\n",
        "<br>\n",
        "\n",
        "<br>\n",
        "\n",
        "![Matriz de confusão para o caso binário e medidas de avaliação](confusion_matrix.png){fig-align='center'}\n",
        "\n",
        "## O sonho da matriz de confusão perfeita {.smaller}\n",
        "\n",
        "- Isso pode acontecer em treinamento, mas é muito improvável em teste e constuma indicar sobreajuste (*overfitting*).\n",
        "\n",
        "![Exemplo de matriz de confusão perfeita para o caso binário](perfect_cm.jpeg){fig-align='center'}\n",
        "\n",
        "## Identificando problemas na matriz de confusão {.smaller}\n",
        "\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "\n",
        "<br>\n",
        "\n",
        "![](exemplo_cm1.jpeg)\n",
        ":::\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "\n",
        "<br>\n",
        "\n",
        "\\begin{align*}\n",
        "Acc&=\\frac{TP+TN}{TP+FP+TN+FN}\\\\\n",
        "&=\\frac{10+1000}{10+20+1000+40}\\\\\n",
        "&=\\frac{1010}{1070}\\\\\n",
        "&=0{,}94.\n",
        "\\end{align*}\n",
        "\n",
        "Neste exemplo, temos alta acurácia: só erramos 60 observações, dentre 1070.\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "## Identificando problemas na matriz de confusão {.smaller}\n",
        "\n",
        "- Vamos calcular a precisão e a cobertura (*recall*), para avaliar o desempenho com relação à classe positiva.\n",
        "\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "![](exemplo_cm1.jpeg)\n",
        ":::\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "\\begin{align*}\n",
        "Prec&=\\frac{TP}{TP+FP}\\\\\n",
        "&=\\frac{10}{10+20}=0{,}33\\\\\n",
        "Rec&=\\frac{TP}{TP+FN}\\\\\n",
        "&=\\frac{10}{10+40}=0{,}20.\n",
        "\\end{align*}\n",
        "\n",
        "Apesar da alta acurácia, o classificador tem péssimo desempenho para a classe positiva.\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "## Identificando problemas na matriz de confusão {.smaller}\n",
        "\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "\n",
        "<br>\n",
        "\n",
        "![](exemplo_cm2.jpeg)\n",
        ":::\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "\n",
        "<br>\n",
        "\n",
        "\\begin{align*}\n",
        "Acc&=\\frac{TP+TN}{TP+FP+TN+FN}\\\\\n",
        "&=\\frac{1020}{1070}\\\\\n",
        "&=0{,}95.\n",
        "\\end{align*}\n",
        "\n",
        "Na verdade, um classificador que apenas \"chute\" que todas as observações são da classe negativa tem maior acurácia.\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "## Identificando problemas na matriz de confusão {.smaller}\n",
        "\n",
        "- Portanto, é importante não \"confiar cegamente\" no resultado de acurácia de seu classificador, principalmente se a proporção de observações de uma classe for muito maior do que a proporção de observações da outra;\n",
        "\n",
        "- Uma boa regra é ter em mente as proporções das classes no conjunto de dados: você deve esperar que seu classificador tenha acurácia pelo menos maior do que a proporção da maior classe.\n",
        "\n",
        "![](confiar.jpeg){fig-align='center'}\n",
        "\n",
        "## *Over/Underfitting* (Sobre/Sob-ajuste) {.smaller}\n",
        "\n",
        "<br>\n",
        "\n",
        "<br>\n",
        "\n",
        "![](overunder.jpeg){fig-align='center'}\n",
        "\n",
        "## *Over/Underfitting* (Sobre/Sob-ajuste) {.smaller}\n",
        "\n",
        "- Essas condições de ajuste podem ser detectadas se compararmos as acurácias ou matrizes de confusão de treinamento e de teste;\n",
        "\n",
        "- *Underfitting* mostrará desempenhos de treinamento e teste parecidos e ruins;\n",
        "\n",
        "- *Overfitting* aparecerá como um desempenho de treinamento muito bom (às vezes perfeito) acompanhado de desempenho de teste péssimo;\n",
        "\n",
        "- Ajuste apropriado aparece como desempenhos de treinamento e teste parecidos e razoáveis/bons.\n",
        "\n",
        "## *Over/Underfitting* (Sobre/Sob-ajuste) em regressão {.smaller}\n",
        "\n",
        "<br>\n",
        "\n",
        "<br>\n",
        "\n",
        "![](reg_overunder.jpeg){fig-align='center'}\n",
        "\n",
        "## Curva ROC {.smaller}\n",
        "\n",
        "- A curva ROC é utilizada para visualizar as diferentes taxas de verdadeiros/falsos positivos de acordo com diferentes limiares.\n",
        "\n",
        "![Ilustração de uma curva ROC](roc_curve.jpeg){fig-align='center'}\n",
        "\n",
        "## Curva ROC {.smaller}\n",
        "\n",
        ":::: {.columns}\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "- Idealmente, queremos que a forma da curva se aproxime ao máximo da forma de um triângulo, ou seja, queremos que a curva se aproxime ao máximo do canto superior esquerdo ou ponto $[0,1]$;\n",
        "\n",
        "- A área embaixo da curva ROC (AUC ou AUROC) indica o quão bom é o desempenho de um classificador independentemente do limiar;\n",
        "\n",
        "- Um classificador aleatório tem AUC$=0{,}5$.\n",
        ":::\n",
        "\n",
        "::: {.column width=\"50%\"}\n",
        "![](roc_curve.jpeg){fig-align='center'}\n",
        ":::\n",
        "\n",
        "::::\n",
        "\n",
        "# Particionamento de dados\n",
        "\n",
        "## Particionamento de dados {.smaller}\n",
        "\n",
        "- Precisamos lembrar que os conjuntos de dados que utilizamos para treinar e testar modelos são, em geral, amostras, e não a população inteira;\n",
        "\n",
        "- Além disso, raramente podemos garantir que as amostras foram obtidas seguindo processos estatisticamente corretos;\n",
        "\n",
        "- Para tomarmos decisões com significância estatística, precisamos usar nossas amostras de forma que possamos extrair o máximo de informação;\n",
        "\n",
        "- Algumas estratégias nos ajudam simular quão bem um modelo de aprendizagem de máquina é capaz de generalizar seu aprendizado na prática.\n",
        "\n",
        "\n",
        "## _Holdout_ {.smaller}\n",
        "\n",
        "- *Holdout* consiste em particionar nosso conjunto de dados em dois conjuntos disjuntos, um conjunto de treinamento, que usamos para treinar os modelos, e um conjunto de teste, usado para avaliar o poder de generalização dos modelos;\n",
        "\n",
        "- Não há uma regra estabelecida para o percentual de observações nos conjuntos de treinamento e teste;\n",
        "\n",
        "- Em geral seleciona-se entre 70% e 80% das amostras para o conjunto de treinamento, e o restante para o conjunto de teste;\n",
        "\n",
        "- Para que as proporções de observações entre as classes (tarefa de classificação) ou entre quantis determinados da variável alvo (tarefa de regressão) sejam mantidas, deve-se usar amostragem aleatória estratificada;\n",
        "\n",
        "- A fim de se avaliar os modelos em diferentes subamostras pode-se repetir o processo de particionamento um número de vezes (*holdout* repetido).\n",
        "\n",
        "## _Holdout_ {.smaller}\n",
        "\n",
        "![Esquema de particionamento *holdout*](holdout.png){fig-align='center'}\n",
        "\n",
        "## $K$-*fold cross-validation* {.smaller}\n",
        "\n",
        "- Validação cruzada é usada para avaliar a capacidade do modelo de reagir corretamente a dados que não foram usados para treiná-lo;\n",
        "\n",
        "- Pode ajudar a detectar problemas como over/underfitting e seleção enviesada de amostras;\n",
        "\n",
        "- Seu funcionamento é simples: divide-se o conjunto em $K$ subconjuntos (*folds*) e, a cada rodada, usa-se um subconjunto para teste (validação) e os outros para treinamento;\n",
        "\n",
        "- Esse processo faz com que os conjuntos de treinamento e teste (validação) sejam disjuntos;\n",
        "\n",
        "- Assim como no *holdout*, deve-se utilizar amostragem aleatória estratificada.\n",
        "\n",
        "## $K$-*fold cross-validation* {.smaller}\n",
        "\n",
        "![Esquema de particionamento $K$-*fold cross-validation*](kfoldcrossvalidation.png){fig-align='center'}\n",
        "\n",
        "# Otimização de hiperparâmetros\n",
        "\n",
        "## Otimização de hiperparâmetros {.smaller}\n",
        "\n",
        "- Um hiperparâmetro é um parâmetro que controla o processo de aprendizagem.\n",
        "  - Note a diferença para os parâmetros que são aprendidos pelo ajuste do modelo, como pesos de redes neurais ou coeficientes da regressão;\n",
        "\n",
        "- Cada algoritmo pode precisar de diferentes valores de hiperparâmetros que influenciam a capacidade de ajustar o modelo aos dados;\n",
        "\n",
        "- Assim, a otimização (*tuning*) de hiperparâmetros é um processo que busca encontrar a tupla de valores de hiperparâmetros que produzem o melhor modelo para um dado problema e uma dada métrica de avaliação.\n",
        "  - Costuma ser feita por meio de validação cruzada.\n",
        "\n",
        "## Otimização de hiperparâmetros {.smaller}\n",
        "\n",
        "![Esquema de particionamento *Holdout* combinado com $K$-*fold cross-validation*](holdout_kfoldcrossvalidation_v2.png){fig-align='center'}\n",
        "\n",
        "## *Grid search* {.smaller}\n",
        "\n",
        "- Trata-se de uma busca exaustiva através de todas as tuplas possíveis de hiperparâmetros dados valores aceitáveis para cada hiperparâmetro, fornecidos pelo usuário;\n",
        "\n",
        "- É necessário especificar uma métrica de performance;\n",
        "\n",
        "- Para parâmetros com suporte em subconjuntos de $\\mathbb{R}$ (contínuos), é necessário definir limites e discretizar seus valores;\n",
        "\n",
        "- Por exemplo, para um classificador SVM com kernel RBF (Gaussiano) precisamos otimizar pelo menos dois hiperparâmetros: o parâmetro de regularização $C$ e a largura do kernel $\\gamma$;\n",
        "\n",
        "## *Grid search* {.smaller}\n",
        "\n",
        "- Ambos são contínuos, então definimos um conjunto finito de valores razoáveis para nossa busca:\n",
        "            \\begin{align*}\n",
        "                C &\\in \\{10, 100, 1000\\}\\\\\n",
        "                \\gamma &\\in \\{0.1, 0.2, 0.5, 1.0\\}\n",
        "            \\end{align*}\n",
        "\n",
        "- O *grid search* vai então treinar um SVM com cada par $(C, \\gamma)$ possível e avaliá-lo no conjunto de validação;\n",
        "\n",
        "- Ao final do processo de validação cruzada, a melhor configuração $(C, \\gamma)$ é retornada;\n",
        "\n",
        "- O processo todo é altamente paralelizável.\n",
        "\n",
        "## *Grid search via racing* {.smaller}\n",
        "\n",
        "- Um problema de *grid search* é que todos os modelos precisam ser treinados com todas as tuplas de hiperparâmetros em todas as subamostras do processo de validação cruzada;\n",
        "\n",
        "- Seria útil se, em algum ponto do processo de otimização, uma análise intermediária fosse realizada, eliminando as tuplas que produziram resultados muito ruins;\n",
        "\n",
        "- Em métodos de *racing*, o processo de otimização avalia todos os modelos em um subconjunto inicial das subamostras (amostras *burn in*);\n",
        "\n",
        "- Com base nas métricas de performance calculadas, algumas tuplas de hiperparâmetros não são consideradas para as subamostras subsequentes;\n",
        "\n",
        "- Essa medida, torna o processo de otimização dos hiperparâmetros mais rápido, peincipalmente para modelos com muitos hiperparâmetros a serem otimizados, como redes neurais e *extreme gradient boosting*.\n",
        "\n",
        "## Para terminar (por hoje...) {.smaller}\n",
        "\n",
        "- As bibliotecas de aprendizagem de máquina costumam ter implementações de métodos de otimização de hiperparâmetros (grid search, grid search via racing, random search, otimização bayesiana, algoritmos evolutivos, inteligência de enxames, etc.);\n",
        "\n",
        "- Para garantir a reprodutibilidade do código, é importante definir uma semente para o gerador de números aleatórios (em `R`, utilizando a função `set.seed()`).\n",
        "\n",
        "## Fim {.smaller}\n",
        "\n",
        "![](fim.jpeg){fig-align=center}\n",
        "\n",
        "## Obrigado Pela Atenção! {.center}\n",
        "\n",
        "\n",
        "```{css}\n",
        ".center h2 {\n",
        "  text-align: center;\n",
        "}\n",
        "```"
      ],
      "id": "14943df0"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}